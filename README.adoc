= Real-Time Analytics with Apache Flink and Apache Pinot
:toc:
:toc-placement: preamble
:source-highlighter: highlight.js

A real-time analytics platform built with Apache Flink and Apache Pinot, designed to process and analyze product analytics data in real-time.

== Quick Start

=== Prerequisites
* Docker and Docker Compose
* Python 3.9+
* Poetry (Python package manager)
* Java 17+
* Gradle

=== Running the Platform

1. Start the infrastructure:
[source,bash]
----
docker compose up -d
----

2. Start the event generator:
[source,bash]
----
cd generator
poetry install
poetry run python -m analytics_generator
----

3. Launch the analytics dashboard:
[source,bash]
----
cd dashboard
poetry install
poetry run streamlit run src/analytics_dashboard/app.py
----

== Architecture Overview

The project consists of the following components:

* Event Generator (Python) - Generates synthetic product analytics events
* Apache Kafka 3.8.0 (Message Queue) - Running in KRaft mode without Zookeeper
* Apache Flink (Stream Processing) - Processes and aggregates events
* Apache Pinot (Real-time OLAP) - Stores and queries analytics data
* Streamlit Dashboard - Visualizes product analytics metrics
* Kafka UI (Monitoring) - Monitors Kafka topics and messages

=== Architecture Diagram

[mermaid]
----
graph LR
    GEN[Event Generator Python]
    RAW[Kafka topic: raw-events]
    PA[Kafka topic: product-analytics]
    AUPM[Kafka topic: active-users-per-minute]
    USA[Kafka topic: user-session-analytics]
    FLINK[Flink SQL Job aggregations & upserts]
    CTRL[Pinot Controller :9000]
    BRK[Pinot Broker :8099]
    SRV[Pinot Server :8097]
    UI[Streamlit Dashboard]

    GEN -->|JSON events| RAW
    RAW --> FLINK
    FLINK -->|upsert| PA
    FLINK -->|upsert| AUPM
    FLINK -->|upsert| USA

    PA --> SRV
    AUPM --> SRV
    USA --> SRV

    UI -->|SQL queries| BRK
    BRK --> SRV
    CTRL --> BRK
    CTRL --> SRV

    KafkaUI[Kafka UI :8080] -. monitors .-> RAW
    FlinkUI[Flink Dashboard :8081] -. monitors .-> FLINK
----

=== End-to-End Data Flow

[mermaid]
----
sequenceDiagram
    autonumber
    participant Gen as Event Generator
    participant Kraw as Kafka (raw-events)
    participant Flink as Flink SQL Job
    participant Kagg as Kafka (upsert topics)
    participant Pinot as Pinot (Server/Broker)
    participant Dash as Streamlit Dashboard

    Gen->>Kraw: Produce JSON events
    Flink-->>Kraw: Consume events (earliest-offset, JSON)
    Flink->>Kagg: Upsert aggregates product-analytics, active-users-per-minute, user-session-analytics
    Kagg->>Pinot: Real-time ingestion (servers consume topics)
    Dash->>Pinot: SQL queries to Broker (:8099)
    Pinot-->>Dash: Result rows for charts/metrics
----

== Product Analytics Dashboard

The dashboard provides real-time insights into product performance and revenue metrics:

=== Features
* Real-time metrics updates with configurable auto-refresh
* Preset time range selections (24h, 7d, 30d, custom)
* Product performance analysis
* Revenue tracking and analysis
* Conversion funnel visualization

=== Key Metrics
* View counts
* Cart additions
* Purchase conversions
* Revenue tracking
* Product category analysis

=== Data Schema

The `product_analytics` table in Pinot contains the following fields:

==== Dimension Fields
* `product_id` (string)
* `product_name` (string)
* `product_category` (string)

==== Metric Fields
* `view_count` (int)
* `cart_adds` (int)
* `purchases` (int)
* `revenue` (double)

==== Time Field
* `update_time` (timestamp in EPOCH milliseconds)

== Development

=== Project Structure
[source]
----
.
├── dashboard/           # Streamlit analytics dashboard
├── generator/           # Event generator
├── flink/              # Flink processing jobs
├── pinot/              # Pinot schema and table configs
└── docker-compose.yml  # Infrastructure setup
----

=== Python Projects
Both Python projects (dashboard and generator) use Poetry for dependency management:

[source,bash]
----
poetry install  # Install dependencies
poetry run     # Run Python scripts
----

=== Contributing
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

== License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.

== Contact

For questions and support, please open an issue on GitHub: https://github.com/gAmUssA/rta-with-flink-pinot/issues
